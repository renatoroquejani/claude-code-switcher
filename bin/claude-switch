#!/bin/bash
VERSION="2.1.0"
SETTINGS="$HOME/.claude/settings.json"
BACKUP_DIR="$HOME/.claude/backups"

# Colors
GREEN=$'\033[0;32m'
YELLOW=$'\033[1;33m'
RED=$'\033[0;31m'
BLUE=$'\033[0;34m'
CYAN=$'\033[0;36m'
BOLD=$'\033[1m'
NC=$'\033[0m'

mkdir -p "$BACKUP_DIR"

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# MODEL MAPPING
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Maps Claude Code model tiers (Opus, Sonnet, Haiku) to provider-specific models

# Anthropic Claude (official)
get_anthropic_models() {
  echo "opus:claude-opus-4-6 sonnet:claude-sonnet-4-5-20250929 haiku:claude-haiku-4-20250920"
}

# Z.AI (GLM models)
get_zai_models() {
  # GLM-4.7 for Opus/Sonnet (best models), GLM-4.5-Flash for Haiku (fast)
  echo "opus:glm-4.7 sonnet:glm-4.7 haiku:glm-4.5-flash"
}

# DeepSeek
get_deepseek_models() {
  # deepseek-chat (capable), deepseek-coder (coding focused)
  echo "opus:deepseek-chat sonnet:deepseek-chat haiku:deepseek-chat"
}

# Kimi (Moonshot AI)
get_kimi_models() {
  echo "opus:moonshot-v1-128k sonnet:moonshot-v1-32k haiku:moonshot-v1-8k"
}

# Qwen (SiliconFlow)
get_qwen_models() {
  # Different sizes of Qwen2.5-Coder
  echo "opus:Qwen/Qwen2.5-Coder-32B-Instruct sonnet:Qwen/Qwen2.5-Coder-14B-Instruct haiku:Qwen/Qwen2.5-Coder-7B-Instruct"
}

# OpenRouter (user specifies model, all tiers use the same)
get_openrouter_models() {
  # Model is specified by user, all tiers map to same model
  local model="${OPENROUTER_DEFAULT_MODEL:-anthropic/claude-opus-4}"
  echo "opus:$model sonnet:$model haiku:$model"
}

# Ollama (local, tiered models by default)
get_ollama_models() {
  # Qwen3-Coder tiered models (7b is default for local use)
  local installed=$(ollama list 2>/dev/null | tail -n +2 | awk '{print $1}')
  local opus="qwen3-coder:32b" sonnet="qwen3-coder:14b" haiku="qwen3-coder:7b"

  # Fallback to available models
  echo "$installed" | grep -q "^${opus}" || opus="$sonnet"
  echo "$installed" | grep -q "^${opus}" || opus="$haiku"
  echo "$installed" | grep -q "^${sonnet}" || sonnet="$opus"
  echo "$installed" | grep -q "^${haiku}" || haiku="$sonnet"

  # If still nothing, use first available
  if [ -z "$opus" ]; then
    opus=$(echo "$installed" | head -1)
    sonnet="$opus"
    haiku="$opus"
  fi

  echo "opus:$opus sonnet:$sonnet haiku:$haiku"
}

# LM Studio (local, single model for all tiers)
get_lmstudio_models() {
  # Uses whatever model is loaded in LM Studio
  echo "opus: sonnet: haiku:"
}

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# DOCUMENTATION
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

show_help() {
  echo ""
  echo -e "${BOLD}Claude Code Model Switcher v${VERSION}${NC}"
  echo ""
  echo -e "${YELLOW}USAGE:${NC}"
  echo "  claude-switch <provider>[:model]"
  echo ""
  echo -e "${YELLOW}CLOUD PROVIDERS:${NC}"
  echo "  ${GREEN}claude${NC}            Anthropic Claude (Opus, Sonnet, Haiku)"
  echo "  ${GREEN}zai / z.ai${NC}        Z.AI GLM models (4.7, 4.6, 4.5-Flash)"
  echo "  ${GREEN}deepseek${NC}          DeepSeek Chat/Coder"
  echo "  ${GREEN}kimi${NC}              Kimi (Moonshot AI)"
  echo "  ${GREEN}qwen${NC}              Qwen Coder (7B, 14B, 32B)"
  echo "  ${GREEN}openrouter${NC}        OpenRouter (requires :model)"
  echo ""
  echo -e "${YELLOW}LOCAL PROVIDERS:${NC}"
  echo "  ${CYAN}ollama${NC}             Ollama (local GGUF models)"
  echo "  ${CYAN}lmstudio${NC}           LM Studio (GUI)"
  echo ""
  echo -e "${YELLOW}MODEL MAPPING:${NC}"
  echo "  Each provider maps Claude's model tiers to their specific models:"
  echo "  • Opus tier    → Provider's most capable model"
  echo "  • Sonnet tier  → Provider's balanced model"
  echo "  • Haiku tier   → Provider's fast/compact model"
  echo ""
  echo -e "${YELLOW}EXAMPLES:${NC}"
  echo "  claude-switch claude           # Use Anthropic Claude"
  echo "  claude-switch zai              # Use Z.AI GLM-4.7 (Opus/Sonnet/Haiku mapped)"
  echo "  claude-switch openrouter:qwen/qwen-2.5-coder-32b"
  echo "  claude-switch ollama           # Use local Ollama (qwen3-coder:7b default)"
  echo "  claude-switch ollama:qwen3-coder:14b  # Use specific model"
  echo ""
  echo -e "${YELLOW}SPECIAL COMMANDS:${NC}"
  echo "  ${GREEN}keys${NC}              Show where to get API keys"
  echo "  ${GREEN}list${NC}              List available providers"
  echo "  ${GREEN}status${NC}            Show current configuration"
  echo "  ${GREEN}models <provider>${NC} Show model mapping for provider"
  echo "  ${GREEN}help${NC}              Show this help"
  echo ""
  echo -e "${YELLOW}AVAILABLE ALIASES:${NC}"
  echo "  claude, zai, z.ai, deepseek, kimi, qwen"
  echo ""
}

show_key_docs() {
  echo ""
  echo -e "${BLUE}━━━ WHERE TO GET API KEYS ━━━${NC}"
  echo ""
  echo -e "${YELLOW}CLOUD PROVIDERS:${NC}"
  echo "  ${GREEN}Claude (Anthropic):${NC} Uses Claude Pro subscription (no API key)"
  echo ""
  echo "  ${GREEN}Z.AI:${NC} https://z.ai/manage-apikey/apikey-list"
  echo "    → Plans: \$3/month or \$15/month (annual ~\$180/year)"
  echo "    → Models: GLM-4.7, GLM-4.6, GLM-4.5-Flash"
  echo ""
  echo "  ${GREEN}DeepSeek:${NC} https://platform.deepseek.com/api_keys"
  echo "    → \$0.14/1M input, \$0.28/1M output"
  echo ""
  echo "  ${GREEN}Kimi:${NC} https://platform.moonshot.cn/console/api-keys"
  echo "    → Moonshot AI (may require Chinese phone number)"
  echo ""
  echo "  ${GREEN}Qwen/SiliconFlow:${NC} https://siliconflow.cn/account/ak"
  echo "    → \$0.42/1M tokens (Qwen2.5-Coder)"
  echo ""
  echo "  ${GREEN}OpenRouter:${NC} https://openrouter.ai/keys"
  echo "    → Access to 100+ models, pricing varies"
  echo ""
  echo -e "${YELLOW}LOCAL PROVIDERS:${NC}"
  echo "  ${CYAN}Ollama:${NC} https://ollama.com/download"
  echo "    → Free, private, runs locally"
  echo "    → Install: curl -fsSL https://ollama.com/install.sh | sh"
  echo "    → Download: ollama pull qwen3-coder:7b   # Default (fast)"
  echo "    →          ollama pull qwen3-coder:14b  # Optional (balanced)"
  echo "    →          ollama pull qwen3-coder:32b  # Optional (capable)"
  echo ""
  echo "  ${CYAN}LM Studio:${NC} https://lmstudio.ai/"
  echo "    → GUI for local models"
  echo ""
  echo -e "${BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
  echo ""
}

list_providers() {
  echo ""
  echo -e "${BOLD}Available Providers:${NC}"
  echo ""
  echo -e "${YELLOW}CLOUD (paid):${NC}"
  echo "  claude     - Anthropic Claude (Opus/Sonnet/Haiku)"
  echo "  zai       - Z.AI GLM (4.7/4.6/4.5-Flash)"
  echo "  deepseek  - DeepSeek Chat/Coder"
  echo "  kimi      - Kimi (Moonshot AI)"
  echo "  qwen      - Qwen Coder (32B/14B/7B)"
  echo "  openrouter - OpenRouter (100+ models)"
  echo ""
  echo -e "${YELLOW}LOCAL (free):${NC}"
  echo "  ollama    - Ollama (local GGUF models)"
  echo "  lmstudio  - LM Studio (GUI)"
  echo ""
  echo -e "${YELLOW}Installed Ollama Models:${NC}"
  if command -v ollama &> /dev/null; then
    ollama list 2>/dev/null || echo "  No models installed"
  else
    echo "  Ollama not installed"
  fi
  echo ""
}

show_model_mapping() {
  local provider="$1"

  if [ -z "$provider" ]; then
    echo -e "${RED}Usage: claude-switch models <provider>${NC}"
    echo ""
    echo "Example: claude-switch models zai"
    return 1
  fi

  echo ""
  echo -e "${BOLD}Model Mapping for: ${GREEN}$provider${NC}${BOLD}${NC}"
  echo ""
  echo -e "${YELLOW}Claude Code Tier${NC}  →  ${YELLOW}Provider Model${NC}"
  echo -e "${BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"

  case "$provider" in
    claude|anthropic)
      echo -e "  Opus    →  claude-opus-4-6"
      echo -e "  Sonnet  →  claude-sonnet-4-5-20250929"
      echo -e "  Haiku   →  claude-haiku-4-20250920"
      ;;
    zai|z.ai|glm)
      echo -e "  Opus    →  glm-4.7"
      echo -e "  Sonnet  →  glm-4.7"
      echo -e "  Haiku   →  glm-4.5-flash"
      ;;
    deepseek)
      echo -e "  Opus    →  deepseek-chat"
      echo -e "  Sonnet  →  deepseek-chat"
      echo -e "  Haiku   →  deepseek-chat"
      ;;
    kimi)
      echo -e "  Opus    →  moonshot-v1-128k"
      echo -e "  Sonnet  →  moonshot-v1-32k"
      echo -e "  Haiku   →  moonshot-v1-8k"
      ;;
    qwen)
      echo -e "  Opus    →  Qwen/Qwen2.5-Coder-32B-Instruct"
      echo -e "  Sonnet  →  Qwen/Qwen2.5-Coder-14B-Instruct"
      echo -e "  Haiku   →  Qwen/Qwen2.5-Coder-7B-Instruct"
      ;;
    openrouter)
      local model="${OPENROUTER_DEFAULT_MODEL:-anthropic/claude-opus-4}"
      echo -e "  Opus    →  $model"
      echo -e "  Sonnet  →  $model"
      echo -e "  Haiku   →  $model"
      echo ""
      echo -e "${CYAN}(All tiers use the same OpenRouter model)${NC}"
      ;;
    ollama)
      local installed=$(ollama list 2>/dev/null | tail -n +2 | awk '{print $1}')
      local opus="qwen3-coder:32b" sonnet="qwen3-coder:14b" haiku="qwen3-coder:7b"

      # Show what would actually be used (with fallback)
      echo "$installed" | grep -q "^${opus}" || opus="$sonnet"
      echo "$installed" | grep -q "^${opus}" || opus="$haiku"
      echo "$installed" | grep -q "^${sonnet}" || sonnet="$opus"
      echo "$installed" | grep -q "^${haiku}" || haiku="$sonnet"
      [ -z "$opus" ] && opus=$(echo "$installed" | head -1)

      echo -e "  Opus    →  ${opus:-<not set>}"
      echo -e "  Sonnet  →  ${sonnet:-<not set>}"
      echo -e "  Haiku   →  ${haiku:-<not set>} ${CYAN}(default)${NC}"
      echo ""
      echo -e "${CYAN}(Tiered models: 32b/14b/7b - 7b is default for local use)${NC}"
      ;;
    lmstudio)
      echo -e "  Opus    →  <loaded in LM Studio>"
      echo -e "  Sonnet  →  <loaded in LM Studio>"
      echo -e "  Haiku   →  <loaded in LM Studio>"
      echo ""
      echo -e "${CYAN}(Uses whatever model is loaded in LM Studio)${NC}"
      ;;
    *)
      echo -e "${RED}Unknown provider: $provider${NC}"
      echo "Run: claude-switch list"
      return 1
      ;;
  esac
  echo ""
}

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CURRENT CONFIG DETECTION
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

get_current_config() {
  local base_url=$(jq -r '.env.ANTHROPIC_BASE_URL // "oauth"' "$SETTINGS" 2>/dev/null)

  case "$base_url" in
    "oauth"|"null") echo "claude" ;;
    *"z.ai"*) echo "zai" ;;
    *"deepseek"*) echo "deepseek" ;;
    *"moonshot"*) echo "kimi" ;;
    *"siliconflow"*) echo "qwen" ;;
    *"openrouter"*) echo "openrouter" ;;
    *"localhost:11434"*|*"127.0.0.1:11434"*) echo "ollama" ;;
    *"localhost:1234"*|*"127.0.0.1:1234"*) echo "lmstudio" ;;
    *) echo "unknown" ;;
  esac
}

get_friendly_name() {
  case "$1" in
    claude|anthropic) echo "Claude (Anthropic)" ;;
    zai|z.ai|glm) echo "Z.AI (GLM)" ;;
    deepseek) echo "DeepSeek" ;;
    kimi) echo "Kimi (Moonshot)" ;;
    qwen) echo "Qwen Coder" ;;
    openrouter) echo "OpenRouter" ;;
    ollama) echo "Ollama (Local)" ;;
    lmstudio) echo "LM Studio (Local)" ;;
    *) echo "Unknown" ;;
  esac
}

show_status() {
  local current=$(get_current_config)
  local current_name=$(get_friendly_name "$current")

  echo ""
  echo -e "${BOLD}Current Status:${NC}"
  echo -e "  Provider: ${GREEN}$current_name${NC}"

  local base_url=$(jq -r '.env.ANTHROPIC_BASE_URL // "oauth"' "$SETTINGS" 2>/dev/null)
  if [ "$base_url" != "oauth" ] && [ "$base_url" != "null" ]; then
    echo "  Base URL: $base_url"
  fi

  local opus_model=$(jq -r '.env.ANTHROPIC_DEFAULT_OPUS_MODEL // "default"' "$SETTINGS" 2>/dev/null)
  if [ "$opus_model" != "default" ] && [ "$opus_model" != "null" ]; then
    echo "  Opus: $opus_model"
  fi

  local sonnet_model=$(jq -r '.env.ANTHROPIC_DEFAULT_SONNET_MODEL // "default"' "$SETTINGS" 2>/dev/null)
  if [ "$sonnet_model" != "default" ] && [ "$sonnet_model" != "null" ]; then
    echo "  Sonnet: $sonnet_model"
  fi

  local haiku_model=$(jq -r '.env.ANTHROPIC_DEFAULT_HAIKU_MODEL // "default"' "$SETTINGS" 2>/dev/null)
  if [ "$haiku_model" != "default" ] && [ "$haiku_model" != "null" ]; then
    echo "  Haiku: $haiku_model"
  fi
  echo ""
}

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# VALIDATIONS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

validate_key() {
  local key_name="$1"
  local key_value="${!key_name}"

  if [ -z "$key_value" ]; then
    echo -e "${RED}❌ $key_name not configured${NC}"
    echo "Configure it in: ~/.claude/api-keys.env"
    echo "Or run: claude-switch keys"
    return 1
  fi
  return 0
}

check_ollama() {
  if ! command -v ollama &> /dev/null; then
    echo -e "${RED}❌ Ollama not installed${NC}"
    echo "Install with: curl -fsSL https://ollama.com/install.sh | sh"
    return 1
  fi

  if ! pgrep -x ollama > /dev/null; then
    echo -e "${YELLOW}⚠️  Ollama is not running${NC}"
    echo "Start with: ollama serve"
    read -p "Start now? [y/N] " -n 1 -r
    echo
    if [[ $REPLY =~ ^[SsYy]$ ]]; then
      nohup ollama serve > /dev/null 2>&1 &
      sleep 2
      echo -e "${GREEN}✓${NC} Ollama started"
    else
      return 1
    fi
  fi
  return 0
}

check_lmstudio() {
  if ! curl -s http://localhost:1234/v1/models > /dev/null 2>&1; then
    echo -e "${RED}❌ LM Studio is not running${NC}"
    echo "Open LM Studio and:"
    echo "1. Load a model"
    echo "2. Go to 'Local Server'"
    echo "3. Click 'Start Server'"
    return 1
  fi
  return 0
}

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# APPLY CONFIGURATIONS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Clear all model-related environment variables
# This prevents stale model settings from leaking between providers
clear_all_models() {
  jq 'del(.env.ANTHROPIC_MODEL,
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL,
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL,
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL)' \
     "$SETTINGS" > "$SETTINGS.tmp"
  mv "$SETTINGS.tmp" "$SETTINGS"
}

apply_config() {
  local provider="$1"
  local override_model="$2"

  # Normalize provider name
  case "$provider" in
    anthropic) provider="claude" ;;
    z.ai|glm) provider="zai" ;;
  esac

  # Backup
  cp "$SETTINGS" "$BACKUP_DIR/settings.json.backup-$(date +%Y%m%d-%H%M%S)"

  # Get model mapping for provider
  local opus_model=""
  local sonnet_model=""
  local haiku_model=""

  case "$provider" in
    claude)
      # Official Anthropic - no API key, no model overrides needed
      clear_all_models
      jq 'del(.env.ANTHROPIC_AUTH_TOKEN, .env.ANTHROPIC_BASE_URL)' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    zai)
      # Check both ZAI_API_KEY and GLM_API_KEY (legacy name)
      local api_key="${ZAI_API_KEY:-$GLM_API_KEY}"
      if [ -z "$api_key" ]; then
        echo -e "${RED}❌ ZAI_API_KEY (or GLM_API_KEY) not configured${NC}"
        echo "Configure it in: ~/.claude/api-keys.env"
        echo "Or run: claude-switch keys"
        return 1
      fi

      # Clear any stale model settings first
      clear_all_models

      # Map tiers to Z.AI models
      opus_model="glm-4.7"
      sonnet_model="glm-4.7"
      haiku_model="glm-4.5-flash"

      jq --arg token "$api_key" \
         --arg opus "$opus_model" \
         --arg sonnet "$sonnet_model" \
         --arg haiku "$haiku_model" \
         '.env.ANTHROPIC_AUTH_TOKEN = $token |
          .env.ANTHROPIC_BASE_URL = "https://api.z.ai/api/anthropic" |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = $opus |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = $sonnet |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = $haiku' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    deepseek)
      validate_key "DEEPSEEK_API_KEY" || return 1

      # Clear any stale model settings first
      clear_all_models

      jq --arg token "$DEEPSEEK_API_KEY" \
         '.env.ANTHROPIC_AUTH_TOKEN = $token |
          .env.ANTHROPIC_BASE_URL = "https://api.deepseek.com/anthropic" |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = "deepseek-chat" |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = "deepseek-chat" |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = "deepseek-chat"' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    kimi)
      validate_key "KIMI_API_KEY" || return 1

      # Clear any stale model settings first
      clear_all_models

      jq --arg token "$KIMI_API_KEY" \
         '.env.ANTHROPIC_AUTH_TOKEN = $token |
          .env.ANTHROPIC_BASE_URL = "https://api.moonshot.ai/anthropic" |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = "moonshot-v1-128k" |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = "moonshot-v1-32k" |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = "moonshot-v1-8k"' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    qwen)
      validate_key "SILICONFLOW_API_KEY" || return 1

      # Clear any stale model settings first
      clear_all_models

      jq --arg token "$SILICONFLOW_API_KEY" \
         '.env.ANTHROPIC_AUTH_TOKEN = $token |
          .env.ANTHROPIC_BASE_URL = "https://api.siliconflow.cn/v1/anthropic" |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = "Qwen/Qwen2.5-Coder-32B-Instruct" |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = "Qwen/Qwen2.5-Coder-14B-Instruct" |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = "Qwen/Qwen2.5-Coder-7B-Instruct"' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    openrouter)
      validate_key "OPENROUTER_API_KEY" || return 1

      # Clear any stale model settings first
      clear_all_models

      # Use override model or default
      if [ -n "$override_model" ]; then
        opus_model="$override_model"
      elif [ -n "$OPENROUTER_DEFAULT_MODEL" ]; then
        opus_model="$OPENROUTER_DEFAULT_MODEL"
      else
        echo -e "${RED}❌ No model specified${NC}"
        echo "Usage: claude-switch openrouter:<model>"
        echo ""
        echo "Popular Claude models on OpenRouter:"
        echo "  anthropic/claude-opus-4       (Claude Opus 4.6 - latest)"
        echo "  anthropic/claude-sonnet-4     (Claude Sonnet 4.5)"
        echo "  anthropic/claude-haiku-4      (Claude Haiku 4.5)"
        echo ""
        echo "Example: claude-switch openrouter:anthropic/claude-opus-4"
        echo ""
        echo "Or set OPENROUTER_DEFAULT_MODEL in ~/.claude/api-keys.env"
        return 1
      fi

      sonnet_model="$opus_model"
      haiku_model="$opus_model"

      jq --arg token "$OPENROUTER_API_KEY" \
         --arg opus "$opus_model" \
         --arg sonnet "$sonnet_model" \
         --arg haiku "$haiku_model" \
         '.env.ANTHROPIC_AUTH_TOKEN = $token |
          .env.ANTHROPIC_BASE_URL = "https://openrouter.ai/api/v1" |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = $opus |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = $sonnet |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = $haiku' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    ollama)
      check_ollama || return 1

      # Clear any stale model settings first
      clear_all_models

      # Default model mapping for Qwen3-Coder tiers (7b is default for local use)
      local default_opus="qwen3-coder:32b"
      local default_sonnet="qwen3-coder:14b"
      local default_haiku="qwen3-coder:7b"

      # Check which models are actually installed
      local installed_models=$(ollama list 2>/dev/null | tail -n +2 | awk '{print $1}')

      # Use override model for all tiers if specified
      if [ -n "$override_model" ]; then
        opus_model="${override_model%:latest}"
        sonnet_model="$opus_model"
        haiku_model="$opus_model"
      else
        # Try to use tiered models, falling back to available ones
        opus_model="qwen3-coder:32b"
        sonnet_model="qwen3-coder:14b"
        haiku_model="qwen3-coder:7b"

        # Check availability and fall back as needed
        if ! echo "$installed_models" | grep -q "^${opus_model}"; then
          opus_model="qwen3-coder:14b"
        fi
        if ! echo "$installed_models" | grep -q "^${opus_model}"; then
          opus_model="qwen3-coder:7b"
        fi
        if ! echo "$installed_models" | grep -q "^${opus_model}"; then
          # Fall back to whatever is available
          opus_model=$(echo "$installed_models" | head -1)
        fi

        # Same logic for sonnet/haiku
        if ! echo "$installed_models" | grep -q "^${sonnet_model}"; then
          sonnet_model="$opus_model"
        fi
        if ! echo "$installed_models" | grep -q "^${haiku_model}"; then
          haiku_model="$sonnet_model"
        fi

        if [ -z "$opus_model" ]; then
          echo -e "${RED}❌ No Ollama models installed${NC}"
          echo "Download models:"
          echo "  ollama pull qwen3-coder:7b   # Haiku tier (default, fast)"
          echo "  ollama pull qwen3-coder:14b  # Sonnet tier"
          echo "  ollama pull qwen3-coder:32b  # Opus tier (if you have RAM)"
          return 1
        fi
      fi

      # Strip :latest tag
      opus_model="${opus_model%:latest}"
      sonnet_model="${sonnet_model%:latest}"
      haiku_model="${haiku_model%:latest}"

      echo -e "${YELLOW}Model mapping:${NC}"
      echo -e "  Opus   → $opus_model"
      echo -e "  Sonnet → $sonnet_model"
      echo -e "  Haiku  → $haiku_model ${CYAN}(default for local)${NC}"

      # Set 7b as the default ANTHROPIC_MODEL for local use
      jq --arg opus "$opus_model" \
         --arg sonnet "$sonnet_model" \
         --arg haiku "$haiku_model" \
         '.env.ANTHROPIC_AUTH_TOKEN = "ollama" |
          .env.ANTHROPIC_BASE_URL = "http://localhost:11434" |
          .env.ANTHROPIC_MODEL = $haiku |
          .env.ANTHROPIC_DEFAULT_OPUS_MODEL = $opus |
          .env.ANTHROPIC_DEFAULT_SONNET_MODEL = $sonnet |
          .env.ANTHROPIC_DEFAULT_HAIKU_MODEL = $haiku' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    lmstudio)
      check_lmstudio || return 1

      # Clear any stale model settings first
      clear_all_models

      jq '.env.ANTHROPIC_AUTH_TOKEN = "lmstudio" |
          .env.ANTHROPIC_BASE_URL = "http://localhost:1234/v1"' \
         "$SETTINGS" > "$SETTINGS.tmp"
      ;;

    *)
      echo -e "${RED}❌ Unknown provider:${NC} $provider"
      echo "Run: claude-switch help"
      return 1
      ;;
  esac

  mv "$SETTINGS.tmp" "$SETTINGS"
  return 0
}

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# MAIN
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Special commands
case "$1" in
  ""|help|-h|--help) show_help; exit 0 ;;
  keys|docs) show_key_docs; exit 0 ;;
  list|ls) list_providers; exit 0 ;;
  status|current) show_status; exit 0 ;;
  models) show_model_mapping "$2"; exit 0 ;;
esac

# Parse provider:model
IFS=':' read -r provider override_model <<< "$1"

# Normalize legacy names
case "$provider" in
  opus) provider="claude" ;;
  z.ai|glm) provider="zai" ;;
esac

# Current status
current=$(get_current_config)
current_name=$(get_friendly_name "$current")

echo -e "${YELLOW}Current status:${NC} $current_name"

# If already on target (and no model override)
if [ "$current" = "$provider" ] && [ -z "$override_model" ]; then
  echo -e "${GREEN}✓${NC} Already configured for $(get_friendly_name "$provider")"
  exit 0
fi

# Confirm switch
target_name=$(get_friendly_name "$provider")
if [ -n "$override_model" ]; then
  target_name="$target_name ($override_model)"
fi

echo -e "${YELLOW}Switch to:${NC} $target_name"
read -p "Confirm? [y/N] " -n 1 -r
echo

if [[ ! $REPLY =~ ^[SsYy]$ ]]; then
  echo "Operation cancelled"
  exit 0
fi

# Apply configuration
if apply_config "$provider" "$override_model"; then
  echo -e "${GREEN}✅ Configured for $target_name${NC}"

  # Show model mapping
  echo ""
  echo -e "${BOLD}Model Mapping:${NC}"
  echo -e "  Opus   → ${GREEN}$(jq -r '.env.ANTHROPIC_DEFAULT_OPUS_MODEL // "default"' "$SETTINGS" 2>/dev/null)${NC}"
  echo -e "  Sonnet → ${GREEN}$(jq -r '.env.ANTHROPIC_DEFAULT_SONNET_MODEL // "default"' "$SETTINGS" 2>/dev/null)${NC}"
  echo -e "  Haiku  → ${GREEN}$(jq -r '.env.ANTHROPIC_DEFAULT_HAIKU_MODEL // "default"' "$SETTINGS" 2>/dev/null)${NC}"

  # Check if Claude Code is running
  if pgrep -f "node.*claude-code" > /dev/null || pgrep -f "@anthropic-ai/claude-code" > /dev/null; then
    echo -e "\n${YELLOW}⚠️  Claude Code is running${NC}"
    read -p "Kill active sessions? [y/N] " -n 1 -r
    echo

    if [[ $REPLY =~ ^[SsYy]$ ]]; then
      pkill -f "node.*claude-code" 2>/dev/null
      pkill -f "@anthropic-ai/claude-code" 2>/dev/null
      echo -e "${GREEN}✓${NC} Sessions terminated"
    fi
  fi

  echo -e "\n${GREEN}✓${NC} Start with: ${BOLD}claude${NC}"
else
  echo -e "${RED}❌ Configuration failed${NC}"
  exit 1
fi
